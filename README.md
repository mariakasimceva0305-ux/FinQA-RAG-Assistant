# FinAnswer: RAG-система для финансового консультирования
Производственная RAG-система (Retrieval-Augmented Generation), разработанная на хакатоне AI for Finance для автоматизации ответов на сложные финансовые вопросы клиентов банка.

## Оглавление
- [Задача хакатона](#задача-хакатона)
- [Наше решение](#наше-решение)
- [Архитектура системы](#архитектура-системы)
- [Ключевые особенности](#ключевые-особенности)
- [Стек технологий](#стек-технологий)
- [Структура проекта](#структура-проекта)
- [Быстрый старт](#быстрый-старт)
- [Результаты и выводы](#результаты-и-выводы)
- [Планы по улучшению](#планы-по-улучшению)
- [Команда](#команда)

## Задача хакатона
За 48 часов создать AI-ассистента, который точно отвечает на финансовые вопросы клиентов, используя базу из 1000+ статей. Требовалось обработать 500 тестовых вопросов с использованием предоставленных API (эмбеддинги, LLM, реранкер).

## Наше решение
Мы построили полнофункциональную RAG-систему с нуля:

**Техническая реализация:**
1. Чанкинг: Разбиение статей на перекрывающиеся отрезки по 800 символов
2. Векторизация: Преобразование чанков в эмбеддинги через text-embedding-3-small
3. Поиск: Косинусная близость + реранкинг через Qwen3-Reranker-4B
4. Генерация: Ответы через Llama-3-70B-Instruct с контекстом

**Показатели:**
- База знаний: 1,000+ финансовых статей
- Обработано вопросов: 500 за один запуск
- Скорость: ~2.5 секунд на вопрос (с кэшированием)
- Надежность: Graceful degradation при сбоях API

## Архитектура системы
```
Вопрос → Векторизация → Поиск по эмбеддингам → Реранкинг → Генерация → Ответ
                    ↑
База знаний → Чанкинг → Векторизация → Кэширование
```

## Ключевые особенности
- Модульная архитектура - легко менять компоненты
- Кэширование эмбеддингов - ускорение в 10+ раз
- Гибкая конфигурация - смена моделей через CLI
- Обработка ошибок - ретраи, фоллбэки
- Пакетная обработка - 500 вопросов за один запуск

## Стек технологий
- Язык: Python 3.10+
- ML/LLM: OpenAI API, Llama 3, Text Embeddings
- Обработка данных: Pandas, NumPy, tqdm
- Инфраструктура: REST API, кэширование, argparse

## Структура проекта
```
financial-qa-rag/
├── main.py # Основной запускаемый файл
├── baseline.py # Базовое решение от организаторов хакатона
├── .env.example # Шаблон для настройки API ключей
├── libraries.txt # Список используемых библиотек
├── questions.csv # 500 тестовых вопросов от клиентов банка
├── requirements.txt # Зависимости Python для воспроизведения проекта
├── train_data.csv # 1000+ финансовых статей (база знаний)
├── src/ # Исходный код RAG-системы
│ ├── config.py # Конфигурация системы и параметры
│ ├── data_loader.py # Загрузка и предобработка данных
│ ├── embedding_service.py # Работа с векторными эмбеддингами
│ ├── retriever.py # Поиск релевантных чанков и реранкинг
│ ├── generator.py # Генерация ответов через LLM
│ └── pipeline.py # Основной пайплайн обработки
└── README.md # Документация проекта
```

## Быстрый старт
```bash
git clone https://github.com/your-username/financial-qa-rag.git
cd financial-qa-rag
pip install -r requirements.txt
cp .env.example .env
python main.py --generate
```

**Параметры командной строки:**
- --generate - генерация ответов для 500 вопросов
- --run_tests - тестирование на 3 вопросах
- --embedding_model - модель для эмбеддингов
- --llm_model - LLM для генерации
- --no_rerank - отключить реранкинг
- --output - путь для сохранения результатов

## Результаты и выводы
**Достижения:**
- Рабочий прототип за 48 часов
- Модульная архитектура
- Производственные практики (обработка ошибок, кэширование)

**Технические инсайты:**
1. Качество чанкинга критически важно
2. Реранкинг дает +10-15% точности, но замедляет систему
3. Кэширование необходимо для производительности
4. Температура 0.3 оптимальна для финансовых ответов

## Планы по улучшению
**Краткосрочные:**
- Гибридный поиск (векторный + keyword)
- Векторная БД (Qdrant/Chroma)
- Веб-интерфейс на Streamlit

**Среднесрочные:**
- Fine-tuning эмбеддера на финансовых текстах
- Локальные модели (SentenceTransformers, Ollama)
- Мониторинг и A/B тестирование
